# Анализатор данных с Multi-LLM

Веб-приложение для анализа табличных данных с помощью различных LLM (OpenAI, YandexGPT, GigaChat).

## Возможности

### Основной функционал
- **Загрузка файлов:** CSV, Excel, PDF
- **Пагинация:** Обработка больших файлов с постраничным отображением
- **Базовый статистический анализ:** Автоматический анализ числовых и категориальных колонок
- **Визуализация данных:** Интерактивные графики с выбором осей
- **Автоматическое построение диаграмм:** Распознавание типов данных и создание графиков
- **Гибкий выбор LLM:** Поддержка OpenAI, YandexGPT, GigaChat с выбором конкретных моделей

### Поддерживаемые модели
**OpenAI:** (слева направо — по убыванию мощности)
- `GPT-4.1` — мощная модель для сложного анализа
- `GPT-4.1 Mini` — эффективная для большинства задач
- `GPT-4.1 Nano` — экономичная для базового анализа

**YandexGPT:** (слева направо — по убыванию мощности)
- `yandexgpt` — полная модель
- `yandexgpt-lite` — быстрая модель

**GigaChat:** (слева направо — по убыванию мощности)
- `GigaChat:latest` — последняя версия
- `GigaChat:latest-9b` — облегчённая версия

### Обработка данных
- **Обработка пропусков:** Интерактивный выбор действий при обнаружении null/NaN/пустых значений:
  - Отбросить строки с пропусками
  - Заполнить средним (только для числовых колонок)
  - **Ручное заполнение** — выбрать значения для каждой колонки с пропусками из выпадающего списка уникальных значений или ввести вручную
  - **Заполнить с помощью ИИ** — получить подсказки для каждого пропуска на основе анализа похожих строк, принять все или отредактировать значения
- **Автоматическая валидация:** Проверка структуры данных и кодировки
- **Обработка ошибок:** Попытка чтения CSV в разных кодировках (UTF-8, CP1251)

### Технические особенности
- **Ограничения файлов:** Максимальный размер 100 МБ
- **Обработка больших CSV:** Файлы >10 МБ ограничиваются первыми 1000 строками
- **Поддержка форматов:** CSV, Excel (.xlsx, .xls), PDF
- **Тестовый режим:** Возможность работы без API-ключей для демонстрации

### Анализ и визуализация
- **Статистика по колонкам:** Минимум, максимум, среднее, количество уникальных значений
- **Интерактивные графики:** Выбор осей X и Y для построения графиков
- **Автоматические диаграммы:** Bar chart для категориальных+числовых, Line chart для дат+значений
- **Пагинация таблицы:** Навигация по большим наборам данных
- **Логирование:** Подробные логи для отладки (DEBUG уровень)
- **Экспорт PDF:** Скачивание отчёта с данными, графиками и анализом

### Фильтрация данных
- Над таблицей доступна панель фильтров:
  - Для категориальных колонок — выпадающие списки уникальных значений.
  - Для числовых — поля для ввода min/max.
  - Для дат — два поля выбора диапазона дат.
  - Кнопка «Сбросить фильтры» для очистки всех фильтров.
- Фильтрация применяется мгновенно, интерфейс адаптивный и современный.

### Визуализация
- Блок ручной визуализации всегда расположен под автоматическим анализом, занимает всю ширину.
- По умолчанию строится график по совету ИИ, пользователь может менять оси X и Y.
- После заполнения пропусков (особенно с помощью ИИ) всегда запускается повторный анализ и обновление графиков.

### Экспорт PDF
- Кнопка экспорта позволяет скачать отчёт с анализом, графиками и первыми строками данных.
- **Выбор типа отчёта:** можно выбрать, что включать в PDF — только аналитику, только данные или оба блока.
- **Визуализация графиков:** в PDF-отчёт автоматически добавляются изображения пользовательского и автоматического графика (если они построены).
- **Имя файла:** если в отчёте есть аналитика, в имени PDF-файла указывается название выбранной LLM-модели (например, `analytics-report-GPT-4_1-2025-07-14.pdf`).

### Пагинация и подгрузка данных
- Для больших файлов реализована кнопка «Показать ещё», позволяющая подгружать данные порциями.
- Backend хранит загруженный файл и возвращает `dataset_id` в ответе `POST /api/upload`.
- Для догрузки последующих страниц используется `POST /api/upload/page` с телом:
  ```json
  {
    "dataset_id": "<из ответа /api/upload>",
    "page": 2,
    "page_size": 1000
  }
  ```
- Сервер выбирает страницу для CSV без полного чтения файла (optimized skiprows + nrows).

### Устойчивость и UX
- Интерфейс устойчив к ошибкам (undefined/null), все действия сопровождаются пояснениями.
- В диалоге ИИ-заполнения только одна кнопка «Применить» с пояснением для пользователя.

## Как работает обработка пропусков

1. **Загрузка файла**
2. **Проверка на пропуски**
   - Если есть пропуски, появляется модальное окно с вариантами:
     - "Отбросить строки с пропусками"
     - "Заполнить пропуски средним (только для числовых колонок)"
     - **"Ручное заполнение"** — для каждой колонки с пропусками можно выбрать значение из выпадающего списка уникальных значений или ввести вручную. Все пропуски в колонке заполняются выбранным значением.
     - **"Заполнить с помощью ИИ"** — для каждой колонки с пропусками запускается анализ похожих строк, предлагаются значения с уровнем уверенности. Можно принять все подсказки одной кнопкой или отредактировать отдельные значения (выпадающий список, ручной ввод). Строки с низкой уверенностью подсвечиваются.
3. **Обработка данных**
   - После выбора и заполнения данные преобразуются
   - Только после этого запускается анализ и визуализация

### UX для ИИ-заполнения пропусков
- Для каждой колонки с пропусками открывается диалог:
  - Таблица строк с пропусками, для каждой — подсказка от ИИ, уровень уверенности, выпадающий список уникальных значений, поле для ручного ввода
  - Кнопки "Применить все подсказки" и "Применить выбранные"
  - Возможность отменить и вернуться к другому способу
  - Строки с низкой уверенностью подсвечиваются

## Как работает автоматическое построение диаграмм

1. **Распознавание типов данных:**
   - Числовые колонки (year, condition, odometer, mmr, sellingprice)
   - Категориальные колонки (make, model, color, etc.)
   - Дата колонки (распознаются по паттернам дат)
2. **Автоматическое создание графиков:**
   - Bar chart: категориальные + числовые (например, make vs sellingprice)
   - Line chart: даты + числовые (например, saledate vs sellingprice)

## Быстрый старт

### Установка зависимостей
```bash
# Бэкенд
pip install -r backend/requirements.txt

# Фронтенд
cd frontend && npm install
```

### Запуск
```bash
# Бэкенд (порт 5000)
cd backend && python pdf_server.py

# Фронтенд (порт 3000)
cd frontend && npm start
```

### Открытие приложения
Перейдите на [http://localhost:3000](http://localhost:3000)

## Запуск через Docker

### Требования
- Docker и Docker Compose

### Локальная разработка (dev режим)

```bash
# Сборка и запуск (backend на :5000, frontend на :3000)
docker compose up --build

# С опциональным override для разработки (hot-reload)
# Создайте docker-compose.override.yml на основе docker-compose.override.yml.example
cp docker-compose.override.yml.example docker-compose.override.yml
# Отредактируйте под свои нужды
docker compose up --build
```

### Production развертывание

```bash
# Создайте .env.prod файл с production переменными
cp env.example .env.prod
# Отредактируйте .env.prod (обязательно установите TEST_MODE=false и API_KEY)

# Запуск production конфигурации
docker compose -f docker-compose.prod.yml --env-file .env.prod up -d

# Просмотр логов
docker compose -f docker-compose.prod.yml logs -f

# Проверка статуса healthcheck
docker compose -f docker-compose.prod.yml ps
```

### Переменные окружения

**Для dev режима (docker-compose.yml):**
```bash
TEST_MODE=true               # демо-режим без реальных ключей
API_KEY=your_api_key         # включить простую API-авторизацию (заголовок X-API-Key)
RATE_LIMIT_WINDOW_SEC=60     # окно для лимита
RATE_LIMIT_MAX_REQ=60       # максимум запросов в окне
```

**Для production (docker-compose.prod.yml):**
См. раздел "Конфигурация" ниже и `docs/DEPLOYMENT.md` для полного списка переменных.

### Доступ
- Frontend: `http://localhost:3000`
- Backend API: `http://localhost:5000/api/*`

Если задан `API_KEY`, все запросы к `/api/*` должны содержать заголовок `X-API-Key: <ваш_ключ>`.

### Healthchecks

Docker контейнеры имеют встроенные healthchecks:
- **Backend**: проверяет `/api/test` endpoint каждые 30 секунд
- **Frontend**: проверяет доступность nginx каждые 30 секунд

Frontend ждет готовности backend перед запуском (`depends_on` с `condition: service_healthy`).

## Конфигурация

### Переменные окружения (.env)
```bash
# OpenAI
OPENAI_API_KEY=your_openai_key_here

# YandexGPT
YANDEX_FOLDER_ID=your_folder_id
YANDEX_API_KEY=your_yandex_key_here

# GigaChat
GIGACHAT_CREDENTIALS=your_gigachat_credentials
GIGACHAT_CERT_PATH=russian_trusted_root_ca.cer
GIGACHAT_VERIFY_SSL_CERTS=true  # false позволяет работать без корневого сертификата (на свой риск)

# Тестовый режим (без API-ключей)
TEST_MODE=true

# Кэш анализа (секунды/лимит)
ANALYSIS_CACHE_TTL_SEC=600
ANALYSIS_CACHE_MAX=256

# Простая авторизация и rate limiting
API_KEY=your_api_key
RATE_LIMIT_WINDOW_SEC=60
RATE_LIMIT_MAX_REQ=60
```

### Переменные окружения (Frontend)
Добавьте в `frontend/.env`:
```bash
# Базовый URL backend API
REACT_APP_API_URL=http://localhost:5000

# Включить подробные логи в консоли браузера (dev)
REACT_APP_DEBUG=true
```

### Тестовый режим
Для демонстрации без API-ключей установите `TEST_MODE=true` в `.env`. В этом режиме:
- LLM возвращают шаблонные ответы
- Все функции работают, но без реального анализа
- Полезно для тестирования интерфейса

### Настройка GigaChat и SSL-сертификаты
По умолчанию для работы с GigaChat требуется корневой сертификат `russian_trusted_root_ca.cer`. Если у вас нет установленного корневого сертификата, вы можете отключить проверку SSL-сертификатов, установив `GIGACHAT_VERIFY_SSL_CERTS=false` в `.env`.

**⚠️ ВАЖНО: Отключение проверки SSL-сертификатов небезопасно!** При `GIGACHAT_VERIFY_SSL_CERTS=false` приложение не будет проверять подлинность сертификата сервера GigaChat, что делает соединение уязвимым для атак "человек посередине" (MITM). Используйте этот параметр только в тестовых окружениях или если вы полностью понимаете связанные риски безопасности. В production всегда используйте `GIGACHAT_VERIFY_SSL_CERTS=true` с корректным файлом сертификата.

## Тестирование и типизация

### Backend (pytest + mypy)
```bash
pytest -q                 # запустить тесты
mypy backend              # статическая проверка типов
```
В CI тесты выполняются с `TEST_MODE=true`, WeasyPrint и кэш анализа активны.

## Ограничения и особенности

### Размеры файлов
- **Максимальный размер:** 100 МБ
- **Большие CSV:** Файлы >10 МБ ограничиваются первыми 1000 строками
- **Ошибка 413:** Автоматическая обработка при превышении лимита

### Обработка файлов
- **CSV:** Поддержка UTF-8 и CP1251 кодировок
- **Excel:** Чтение всех листов (.xlsx, .xls)
- **PDF:** Извлечение первой таблицы с первой страницы
- **Ошибки кодировки:** Автоматическая попытка альтернативной кодировки

### Валидация данных
- **Frontend:** Строгая проверка структуры ответа от backend
- **Backend:** Логирование всех операций (DEBUG уровень)
- **Обработка NaN:** Автоматическая замена на null в JSON

## Пример UX при пропусках

```
В данных обнаружены пропуски:
- Колонка "body": 5 строк
- Колонка "sellingprice": 2 строки
Что сделать с пропусками?
[ ] Отбросить строки с пропусками
[ ] Заполнить пропуски средним (только для числовых колонок)
[ ] Ручное заполнение
[ ] Заполнить с помощью ИИ
[Продолжить]
```

## Архитектура

### Backend (Python/Flask)
- **pdf_server.py:** Основной сервер с API endpoints
- **llm/:** Модули для работы с LLM провайдерами
  - `main_processor.py` — центральная точка вызова LLM
  - `openai_helper.py` — работа с OpenAI
  - `yandex_gpt_helper.py` — работа с YandexGPT
  - `gigachat_helper.py` — работа с GigaChat

### Frontend (React/TypeScript)
- **App.tsx:** Основной компонент с логикой обработки пропусков
- **components/:** UI компоненты
  - `FileUpload.tsx` — загрузка файлов
  - `ModelSelector.tsx` — выбор модели LLM
  - `AnalysisResult.tsx` — отображение результатов с автоматическими диаграммами
  - `ManualFillDialog.tsx` — ручное заполнение пропусков
  - `AIFillDialog.tsx` — ИИ-заполнение пропусков с подсказками
- **api/:** HTTP клиент с валидацией ответов
- **types/:** TypeScript типы

### API Endpoints
- `POST /api/upload` — загрузка файла (CSV, Excel, PDF)
- `POST /api/analyze` — анализ данных LLM
- `POST /api/report` — генерация PDF отчёта
- `POST /api/fill-missing-ai` — ИИ-подсказки для заполнения пропусков
- `GET /api/test` — проверка работоспособности

## TODO/Планы
- Заполнение пропусков с помощью ИИ (LLM) для сложных случаев
- Расширенное построчное ручное заполнение
- Расширенная статистика и визуализация
- Настраиваемый размер страницы в интерфейсе
- Кэширование результатов анализа
- Улучшенная обработка больших файлов

---

**Проект развивается!**

---

**Автор:** Георгий Белянин (Georgy Belyanin) — georgy.belyanin@gmail.com

Репозиторий: `https://github.com/ergon73/multi-llm-data-analyzer`
